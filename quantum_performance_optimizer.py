#!/usr/bin/env python3
"""
üõ°Ô∏è QuantumShield - Performance Optimizer
Arquivo: quantum_performance_optimizer.py
Descri√ß√£o: Sistema de otimiza√ß√£o de performance para QuantumShield
Autor: QuantumShield Team
Vers√£o: 2.0
Data: 03/07/2025
"""

import os
import sys
import time
import psutil
import threading
import logging
import json
import gc
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, asdict
from pathlib import Path
import cProfile
import pstats
import io
from contextlib import contextmanager

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class PerformanceMetrics:
    """M√©tricas de performance"""
    cpu_usage: float
    memory_usage: float
    memory_peak: float
    execution_time: float
    function_calls: int
    cache_hits: int
    cache_misses: int
    thread_count: int
    io_operations: int

@dataclass
class OptimizationResult:
    """Resultado da otimiza√ß√£o"""
    before_metrics: PerformanceMetrics
    after_metrics: PerformanceMetrics
    improvement_percentage: float
    optimizations_applied: List[str]
    recommendations: List[str]

class QuantumPerformanceOptimizer:
    """Sistema de otimiza√ß√£o de performance QuantumShield"""
    
    def __init__(self):
        # Cache para otimiza√ß√µes
        self.function_cache = {}
        self.result_cache = {}
        self.cache_stats = {'hits': 0, 'misses': 0}
        
        # M√©tricas de performance
        self.metrics_history = []
        self.profiling_enabled = True
        
        # Configura√ß√µes de otimiza√ß√£o
        self.optimization_config = {
            'enable_caching': True,
            'enable_threading': True,
            'enable_memory_optimization': True,
            'enable_io_optimization': True,
            'enable_cpu_optimization': True,
            'max_cache_size': 1000,
            'max_threads': min(8, os.cpu_count() or 4),
            'gc_threshold': 100
        }
        
        # Thread pool para opera√ß√µes ass√≠ncronas
        self.thread_pool = []
        self.thread_lock = threading.Lock()
        
        # Contadores de performance
        self.performance_counters = {
            'function_calls': 0,
            'cache_operations': 0,
            'io_operations': 0,
            'memory_allocations': 0
        }
        
        logger.info("‚ö° Sistema de otimiza√ß√£o de performance inicializado")
    
    @contextmanager
    def performance_monitor(self, operation_name: str):
        """Context manager para monitorar performance"""
        start_time = time.perf_counter()
        start_memory = psutil.Process().memory_info().rss
        start_cpu = psutil.cpu_percent()
        
        try:
            yield
        finally:
            end_time = time.perf_counter()
            end_memory = psutil.Process().memory_info().rss
            end_cpu = psutil.cpu_percent()
            
            execution_time = end_time - start_time
            memory_delta = end_memory - start_memory
            cpu_delta = end_cpu - start_cpu
            
            logger.debug(f"üìä {operation_name}: {execution_time:.3f}s, "
                        f"Mem: {memory_delta/1024/1024:.1f}MB, CPU: {cpu_delta:.1f}%")
    
    def cached_function(self, cache_key: str = None, ttl: int = 3600):
        """Decorator para cache de fun√ß√µes"""
        def decorator(func: Callable):
            def wrapper(*args, **kwargs):
                # Gerar chave de cache
                if cache_key:
                    key = f"{cache_key}_{hash(str(args) + str(kwargs))}"
                else:
                    key = f"{func.__name__}_{hash(str(args) + str(kwargs))}"
                
                # Verificar cache
                if self.optimization_config['enable_caching']:
                    cached_result = self._get_from_cache(key)
                    if cached_result is not None:
                        self.cache_stats['hits'] += 1
                        return cached_result
                
                # Executar fun√ß√£o
                self.cache_stats['misses'] += 1
                self.performance_counters['function_calls'] += 1
                
                with self.performance_monitor(func.__name__):
                    result = func(*args, **kwargs)
                
                # Armazenar no cache
                if self.optimization_config['enable_caching']:
                    self._store_in_cache(key, result, ttl)
                
                return result
            
            return wrapper
        return decorator
    
    def _get_from_cache(self, key: str) -> Any:
        """Obt√©m valor do cache"""
        try:
            if key in self.function_cache:
                cached_item = self.function_cache[key]
                
                # Verificar TTL
                if time.time() - cached_item['timestamp'] < cached_item['ttl']:
                    return cached_item['value']
                else:
                    # Cache expirado
                    del self.function_cache[key]
            
            return None
            
        except Exception as e:
            logger.error(f"‚ùå Erro no cache: {e}")
            return None
    
    def _store_in_cache(self, key: str, value: Any, ttl: int):
        """Armazena valor no cache"""
        try:
            # Verificar limite do cache
            if len(self.function_cache) >= self.optimization_config['max_cache_size']:
                # Remover item mais antigo
                oldest_key = min(self.function_cache.keys(), 
                               key=lambda k: self.function_cache[k]['timestamp'])
                del self.function_cache[oldest_key]
            
            # Armazenar no cache
            self.function_cache[key] = {
                'value': value,
                'timestamp': time.time(),
                'ttl': ttl
            }
            
            self.performance_counters['cache_operations'] += 1
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao armazenar cache: {e}")
    
    def optimize_memory_usage(self):
        """Otimiza uso de mem√≥ria"""
        try:
            logger.info("üß† Otimizando uso de mem√≥ria...")
            
            # For√ßar garbage collection
            collected = gc.collect()
            logger.info(f"   üóëÔ∏è {collected} objetos coletados pelo GC")
            
            # Limpar cache antigo
            current_time = time.time()
            expired_keys = []
            
            for key, cached_item in self.function_cache.items():
                if current_time - cached_item['timestamp'] > cached_item['ttl']:
                    expired_keys.append(key)
            
            for key in expired_keys:
                del self.function_cache[key]
            
            if expired_keys:
                logger.info(f"   üßπ {len(expired_keys)} itens de cache expirados removidos")
            
            # Otimizar estruturas de dados
            self._optimize_data_structures()
            
            # Verificar uso de mem√≥ria
            memory_info = psutil.Process().memory_info()
            memory_mb = memory_info.rss / 1024 / 1024
            
            logger.info(f"   üìä Uso de mem√≥ria atual: {memory_mb:.1f} MB")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erro na otimiza√ß√£o de mem√≥ria: {e}")
            return False
    
    def _optimize_data_structures(self):
        """Otimiza estruturas de dados"""
        try:
            # Converter listas grandes em geradores quando poss√≠vel
            # Otimizar dicion√°rios removendo chaves desnecess√°rias
            # Usar __slots__ em classes quando apropriado
            
            # Exemplo de otimiza√ß√£o
            if hasattr(self, 'large_data_list'):
                # Converter para gerador se for muito grande
                if len(self.large_data_list) > 10000:
                    self.large_data_list = (item for item in self.large_data_list)
            
        except Exception as e:
            logger.error(f"‚ùå Erro na otimiza√ß√£o de estruturas: {e}")
    
    def optimize_cpu_usage(self):
        """Otimiza uso de CPU"""
        try:
            logger.info("üî• Otimizando uso de CPU...")
            
            # Verificar n√∫mero de threads ativas
            active_threads = threading.active_count()
            logger.info(f"   üßµ Threads ativas: {active_threads}")
            
            # Otimizar n√∫mero de threads
            max_threads = self.optimization_config['max_threads']
            if active_threads > max_threads:
                logger.warning(f"   ‚ö†Ô∏è Muitas threads ativas ({active_threads} > {max_threads})")
            
            # Verificar uso de CPU
            cpu_percent = psutil.cpu_percent(interval=1)
            logger.info(f"   üìä Uso de CPU: {cpu_percent:.1f}%")
            
            # Sugerir otimiza√ß√µes baseadas no uso
            if cpu_percent > 80:
                logger.warning("   ‚ö†Ô∏è Alto uso de CPU detectado")
                self._suggest_cpu_optimizations()
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erro na otimiza√ß√£o de CPU: {e}")
            return False
    
    def _suggest_cpu_optimizations(self):
        """Sugere otimiza√ß√µes de CPU"""
        suggestions = [
            "Considere usar threading para opera√ß√µes I/O",
            "Implemente cache para c√°lculos repetitivos",
            "Use algoritmos mais eficientes",
            "Considere processamento ass√≠ncrono",
            "Otimize loops aninhados"
        ]
        
        for suggestion in suggestions:
            logger.info(f"   üí° {suggestion}")
    
    def optimize_io_operations(self):
        """Otimiza opera√ß√µes de I/O"""
        try:
            logger.info("üíæ Otimizando opera√ß√µes de I/O...")
            
            # Verificar opera√ß√µes de disco
            disk_io = psutil.disk_io_counters()
            if disk_io:
                logger.info(f"   üìñ Leituras: {disk_io.read_count}")
                logger.info(f"   üìù Escritas: {disk_io.write_count}")
            
            # Sugest√µes de otimiza√ß√£o I/O
            io_optimizations = [
                "Use buffering para opera√ß√µes de arquivo",
                "Implemente cache para dados frequentemente acessados",
                "Use opera√ß√µes ass√≠ncronas para I/O de rede",
                "Considere compress√£o para dados grandes",
                "Minimize opera√ß√µes de seek em arquivos"
            ]
            
            for optimization in io_optimizations:
                logger.info(f"   üí° {optimization}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erro na otimiza√ß√£o de I/O: {e}")
            return False
    
    def profile_function(self, func: Callable, *args, **kwargs):
        """Faz profiling de uma fun√ß√£o"""
        try:
            logger.info(f"üìä Fazendo profiling de {func.__name__}...")
            
            # Criar profiler
            profiler = cProfile.Profile()
            
            # Executar com profiling
            profiler.enable()
            result = func(*args, **kwargs)
            profiler.disable()
            
            # Analisar resultados
            stats_stream = io.StringIO()
            stats = pstats.Stats(profiler, stream=stats_stream)
            stats.sort_stats('cumulative')
            stats.print_stats(10)  # Top 10 fun√ß√µes
            
            profile_output = stats_stream.getvalue()
            logger.info(f"üìà Profiling de {func.__name__}:")
            for line in profile_output.split('\n')[:15]:  # Primeiras 15 linhas
                if line.strip():
                    logger.info(f"   {line}")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Erro no profiling: {e}")
            return None
    
    def benchmark_operation(self, operation: Callable, iterations: int = 1000) -> Dict[str, float]:
        """Faz benchmark de uma opera√ß√£o"""
        try:
            logger.info(f"‚è±Ô∏è Fazendo benchmark de {operation.__name__} ({iterations} itera√ß√µes)...")
            
            times = []
            memory_usage = []
            
            for i in range(iterations):
                # Medir tempo
                start_time = time.perf_counter()
                start_memory = psutil.Process().memory_info().rss
                
                # Executar opera√ß√£o
                operation()
                
                # Medir fim
                end_time = time.perf_counter()
                end_memory = psutil.Process().memory_info().rss
                
                times.append(end_time - start_time)
                memory_usage.append(end_memory - start_memory)
            
            # Calcular estat√≠sticas
            avg_time = sum(times) / len(times)
            min_time = min(times)
            max_time = max(times)
            avg_memory = sum(memory_usage) / len(memory_usage)
            
            results = {
                'average_time': avg_time,
                'min_time': min_time,
                'max_time': max_time,
                'average_memory_delta': avg_memory,
                'iterations': iterations
            }
            
            logger.info(f"üìä Resultados do benchmark:")
            logger.info(f"   ‚è±Ô∏è Tempo m√©dio: {avg_time*1000:.3f}ms")
            logger.info(f"   ‚ö° Tempo m√≠nimo: {min_time*1000:.3f}ms")
            logger.info(f"   üêå Tempo m√°ximo: {max_time*1000:.3f}ms")
            logger.info(f"   üß† Mem√≥ria m√©dia: {avg_memory/1024:.1f}KB")
            
            return results
            
        except Exception as e:
            logger.error(f"‚ùå Erro no benchmark: {e}")
            return {}
    
    def get_performance_metrics(self) -> PerformanceMetrics:
        """Obt√©m m√©tricas atuais de performance"""
        try:
            process = psutil.Process()
            
            metrics = PerformanceMetrics(
                cpu_usage=psutil.cpu_percent(),
                memory_usage=process.memory_info().rss / 1024 / 1024,  # MB
                memory_peak=process.memory_info().peak_wset / 1024 / 1024 if hasattr(process.memory_info(), 'peak_wset') else 0,
                execution_time=time.time(),
                function_calls=self.performance_counters['function_calls'],
                cache_hits=self.cache_stats['hits'],
                cache_misses=self.cache_stats['misses'],
                thread_count=threading.active_count(),
                io_operations=self.performance_counters['io_operations']
            )
            
            return metrics
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao obter m√©tricas: {e}")
            return PerformanceMetrics(0, 0, 0, 0, 0, 0, 0, 0, 0)
    
    def optimize_all(self) -> OptimizationResult:
        """Executa todas as otimiza√ß√µes"""
        try:
            logger.info("üöÄ Iniciando otimiza√ß√£o completa...")
            
            # M√©tricas antes
            before_metrics = self.get_performance_metrics()
            
            # Aplicar otimiza√ß√µes
            optimizations_applied = []
            
            if self.optimize_memory_usage():
                optimizations_applied.append("Memory optimization")
            
            if self.optimize_cpu_usage():
                optimizations_applied.append("CPU optimization")
            
            if self.optimize_io_operations():
                optimizations_applied.append("I/O optimization")
            
            # M√©tricas depois
            time.sleep(1)  # Aguardar estabiliza√ß√£o
            after_metrics = self.get_performance_metrics()
            
            # Calcular melhoria
            memory_improvement = ((before_metrics.memory_usage - after_metrics.memory_usage) / 
                                before_metrics.memory_usage * 100) if before_metrics.memory_usage > 0 else 0
            
            # Recomenda√ß√µes
            recommendations = self._generate_recommendations(before_metrics, after_metrics)
            
            result = OptimizationResult(
                before_metrics=before_metrics,
                after_metrics=after_metrics,
                improvement_percentage=memory_improvement,
                optimizations_applied=optimizations_applied,
                recommendations=recommendations
            )
            
            logger.info("‚úÖ Otimiza√ß√£o completa conclu√≠da")
            logger.info(f"   üìä Melhoria de mem√≥ria: {memory_improvement:.1f}%")
            logger.info(f"   üîß Otimiza√ß√µes aplicadas: {len(optimizations_applied)}")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Erro na otimiza√ß√£o completa: {e}")
            return OptimizationResult(
                before_metrics=PerformanceMetrics(0, 0, 0, 0, 0, 0, 0, 0, 0),
                after_metrics=PerformanceMetrics(0, 0, 0, 0, 0, 0, 0, 0, 0),
                improvement_percentage=0,
                optimizations_applied=[],
                recommendations=[]
            )
    
    def _generate_recommendations(self, before: PerformanceMetrics, after: PerformanceMetrics) -> List[str]:
        """Gera recomenda√ß√µes de otimiza√ß√£o"""
        recommendations = []
        
        # An√°lise de mem√≥ria
        if after.memory_usage > 100:  # MB
            recommendations.append("Considere otimizar uso de mem√≥ria - uso alto detectado")
        
        # An√°lise de CPU
        if after.cpu_usage > 50:
            recommendations.append("Considere otimizar algoritmos - uso de CPU alto")
        
        # An√°lise de cache
        cache_hit_rate = (after.cache_hits / (after.cache_hits + after.cache_misses) * 100) if (after.cache_hits + after.cache_misses) > 0 else 0
        if cache_hit_rate < 70:
            recommendations.append("Melhore estrat√©gia de cache - taxa de acerto baixa")
        
        # An√°lise de threads
        if after.thread_count > 10:
            recommendations.append("Considere reduzir n√∫mero de threads - muitas threads ativas")
        
        return recommendations
    
    def create_performance_report(self) -> str:
        """Cria relat√≥rio de performance"""
        try:
            metrics = self.get_performance_metrics()
            
            report_data = {
                'timestamp': time.time(),
                'performance_metrics': asdict(metrics),
                'cache_statistics': self.cache_stats,
                'performance_counters': self.performance_counters,
                'optimization_config': self.optimization_config,
                'system_info': {
                    'cpu_count': os.cpu_count(),
                    'total_memory': psutil.virtual_memory().total / 1024 / 1024 / 1024,  # GB
                    'available_memory': psutil.virtual_memory().available / 1024 / 1024 / 1024,  # GB
                    'platform': sys.platform
                }
            }
            
            report_file = f"performance_report_{int(time.time())}.json"
            with open(report_file, 'w') as f:
                json.dump(report_data, f, indent=2, default=str)
            
            logger.info(f"üìä Relat√≥rio de performance criado: {report_file}")
            return report_file
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao criar relat√≥rio: {e}")
            return ""

def test_performance_optimizer():
    """Teste do sistema de otimiza√ß√£o de performance"""
    print("‚ö° Testando Sistema de Otimiza√ß√£o de Performance...")
    
    optimizer = QuantumPerformanceOptimizer()
    
    try:
        # Teste 1: Fun√ß√£o com cache
        @optimizer.cached_function(cache_key="test_function", ttl=60)
        def expensive_calculation(n):
            time.sleep(0.01)  # Simular opera√ß√£o custosa
            return sum(range(n))
        
        print("\nüîÑ Testando cache de fun√ß√£o...")
        
        # Primeira chamada (cache miss)
        start_time = time.perf_counter()
        result1 = expensive_calculation(1000)
        time1 = time.perf_counter() - start_time
        
        # Segunda chamada (cache hit)
        start_time = time.perf_counter()
        result2 = expensive_calculation(1000)
        time2 = time.perf_counter() - start_time
        
        print(f"  üìä Primeira chamada: {time1*1000:.1f}ms")
        print(f"  ‚ö° Segunda chamada: {time2*1000:.1f}ms")
        print(f"  üöÄ Speedup: {time1/time2:.1f}x")
        print(f"  ‚úÖ Cache hits: {optimizer.cache_stats['hits']}")
        
        # Teste 2: Benchmark
        print("\n‚è±Ô∏è Testando benchmark...")
        def simple_operation():
            return sum(range(100))
        
        benchmark_results = optimizer.benchmark_operation(simple_operation, 100)
        print(f"  ‚úÖ Benchmark conclu√≠do: {benchmark_results.get('average_time', 0)*1000:.3f}ms m√©dio")
        
        # Teste 3: Otimiza√ß√£o completa
        print("\nüöÄ Testando otimiza√ß√£o completa...")
        optimization_result = optimizer.optimize_all()
        
        print(f"  üìä Otimiza√ß√µes aplicadas: {len(optimization_result.optimizations_applied)}")
        for opt in optimization_result.optimizations_applied:
            print(f"    ‚úÖ {opt}")
        
        print(f"  üí° Recomenda√ß√µes: {len(optimization_result.recommendations)}")
        for rec in optimization_result.recommendations:
            print(f"    üí° {rec}")
        
        # Teste 4: M√©tricas de performance
        print("\nüìä M√©tricas atuais:")
        metrics = optimizer.get_performance_metrics()
        print(f"  üß† Mem√≥ria: {metrics.memory_usage:.1f} MB")
        print(f"  üî• CPU: {metrics.cpu_usage:.1f}%")
        print(f"  üßµ Threads: {metrics.thread_count}")
        print(f"  üìû Chamadas de fun√ß√£o: {metrics.function_calls}")
        
        # Teste 5: Relat√≥rio
        print("\nüìã Criando relat√≥rio...")
        report_file = optimizer.create_performance_report()
        if report_file:
            print(f"  ‚úÖ Relat√≥rio criado: {report_file}")
        
        print("\n‚úÖ Teste de otimiza√ß√£o de performance conclu√≠do!")
        return True
        
    except Exception as e:
        print(f"\n‚ùå Erro no teste: {e}")
        return False

if __name__ == "__main__":
    test_performance_optimizer()


    
    def measure_network_latency(self, target_host: str = "8.8.8.8") -> float:
        """Medir lat√™ncia de rede"""
        try:
            import subprocess
            import time
            
            start_time = time.time()
            result = subprocess.run(
                ["ping", "-c", "1", target_host],
                capture_output=True,
                text=True,
                timeout=5
            )
            end_time = time.time()
            
            if result.returncode == 0:
                latency = (end_time - start_time) * 1000  # ms
                self.metrics["network_latency"] = latency
                return latency
            else:
                self.metrics["network_latency"] = 999.0  # Timeout
                return 999.0
                
        except Exception as e:
            logger.error(f"Erro ao medir lat√™ncia: {e}")
            self.metrics["network_latency"] = 999.0
            return 999.0
    
    def measure_network_throughput(self) -> float:
        """Medir throughput de rede"""
        try:
            import time
            import requests
            
            # Teste de download simples
            start_time = time.time()
            response = requests.get("http://httpbin.org/bytes/1024", timeout=10)
            end_time = time.time()
            
            if response.status_code == 200:
                bytes_downloaded = len(response.content)
                duration = end_time - start_time
                throughput = (bytes_downloaded * 8) / (duration * 1024 * 1024)  # Mbps
                self.metrics["network_throughput"] = throughput
                return throughput
            else:
                self.metrics["network_throughput"] = 0.0
                return 0.0
                
        except Exception as e:
            logger.error(f"Erro ao medir throughput: {e}")
            self.metrics["network_throughput"] = 0.0
            return 0.0
    
    def measure_network_quality(self) -> dict:
        """Medir qualidade geral da rede"""
        try:
            latency = self.measure_network_latency()
            throughput = self.measure_network_throughput()
            
            # Calcular score de qualidade
            latency_score = max(0, 100 - (latency / 10))  # Penalizar lat√™ncia alta
            throughput_score = min(100, throughput * 10)  # Recompensar throughput alto
            
            quality_score = (latency_score + throughput_score) / 2
            
            quality_data = {
                "latency_ms": latency,
                "throughput_mbps": throughput,
                "quality_score": quality_score,
                "status": "excellent" if quality_score >= 80 else "good" if quality_score >= 60 else "poor"
            }
            
            self.metrics["network_quality"] = quality_data
            return quality_data
            
        except Exception as e:
            logger.error(f"Erro ao medir qualidade da rede: {e}")
            return {"status": "error", "quality_score": 0}

    
    def start_continuous_monitoring(self, interval: int = 30):
        """Iniciar monitoramento cont√≠nuo"""
        try:
            import threading
            import time
            
            def monitor_loop():
                while self.monitoring_active:
                    try:
                        # Coletar todas as m√©tricas
                        self.get_cpu_usage()
                        self.get_memory_usage()
                        self.get_disk_usage()
                        self.measure_network_latency()
                        self.measure_network_throughput()
                        
                        # Salvar hist√≥rico
                        timestamp = time.time()
                        self.metrics_history.append({
                            "timestamp": timestamp,
                            "metrics": self.metrics.copy()
                        })
                        
                        # Manter apenas √∫ltimas 100 medi√ß√µes
                        if len(self.metrics_history) > 100:
                            self.metrics_history.pop(0)
                            
                        time.sleep(interval)
                        
                    except Exception as e:
                        logger.error(f"Erro no monitoramento: {e}")
                        time.sleep(interval)
            
            self.monitoring_active = True
            self.monitoring_thread = threading.Thread(target=monitor_loop, daemon=True)
            self.monitoring_thread.start()
            
            self.log_correction("PERFORMANCE", "Monitoramento cont√≠nuo iniciado", "SUCCESS")
            
        except Exception as e:
            logger.error(f"Erro ao iniciar monitoramento: {e}")
            self.log_correction("PERFORMANCE", f"Erro no monitoramento: {e}", "FAILED")
    
    def stop_continuous_monitoring(self):
        """Parar monitoramento cont√≠nuo"""
        self.monitoring_active = False
        if hasattr(self, 'monitoring_thread'):
            self.monitoring_thread.join(timeout=5)
        self.log_correction("PERFORMANCE", "Monitoramento parado", "SUCCESS")
    
    def get_performance_report(self) -> dict:
        """Obter relat√≥rio completo de performance"""
        try:
            # Coletar m√©tricas atuais
            current_metrics = {
                "cpu_percent": self.get_cpu_usage(),
                "memory_percent": self.get_memory_usage(),
                "disk_percent": self.get_disk_usage(),
                "network_latency": self.measure_network_latency(),
                "network_throughput": self.measure_network_throughput(),
                "network_quality": self.measure_network_quality()
            }
            
            # Calcular score geral
            scores = []
            scores.append(max(0, 100 - current_metrics["cpu_percent"]))
            scores.append(max(0, 100 - current_metrics["memory_percent"]))
            scores.append(max(0, 100 - current_metrics["disk_percent"]))
            scores.append(current_metrics["network_quality"]["quality_score"])
            
            overall_score = sum(scores) / len(scores)
            
            report = {
                "timestamp": time.time(),
                "current_metrics": current_metrics,
                "overall_score": overall_score,
                "status": "excellent" if overall_score >= 80 else "good" if overall_score >= 60 else "poor",
                "recommendations": self.generate_recommendations(current_metrics)
            }
            
            return report
            
        except Exception as e:
            logger.error(f"Erro ao gerar relat√≥rio: {e}")
            return {"status": "error", "overall_score": 0}
    
    def generate_recommendations(self, metrics: dict) -> list:
        """Gerar recomenda√ß√µes baseadas nas m√©tricas"""
        recommendations = []
        
        if metrics["cpu_percent"] > 80:
            recommendations.append("CPU usage high - consider closing unnecessary applications")
        
        if metrics["memory_percent"] > 80:
            recommendations.append("Memory usage high - consider increasing RAM or optimizing memory usage")
        
        if metrics["disk_percent"] > 90:
            recommendations.append("Disk space low - consider cleaning up files or adding storage")
        
        if metrics["network_latency"] > 100:
            recommendations.append("Network latency high - check internet connection")
        
        if metrics["network_throughput"] < 1:
            recommendations.append("Network throughput low - check bandwidth availability")
        
        if not recommendations:
            recommendations.append("System performance is optimal")
        
        return recommendations

# Alias para compatibilidade com testes
PerformanceOptimizer = QuantumPerformanceOptimizer

# Fun√ß√£o de conveni√™ncia para criar otimizador
def create_performance_optimizer():
    """Criar inst√¢ncia do otimizador de performance"""
    return QuantumPerformanceOptimizer()

# Fun√ß√£o para otimiza√ß√£o r√°pida
def quick_optimize():
    """Executar otimiza√ß√£o r√°pida do sistema"""
    optimizer = QuantumPerformanceOptimizer()
    return optimizer.optimize_system()

